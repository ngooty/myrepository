{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('cars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 963 entries, 0 to 962\n",
      "Data columns (total 6 columns):\n",
      "age       963 non-null int64\n",
      "gender    963 non-null int64\n",
      "miles     963 non-null int64\n",
      "debt      963 non-null int64\n",
      "income    963 non-null int64\n",
      "sales     963 non-null int64\n",
      "dtypes: int64(6)\n",
      "memory usage: 45.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('sales',axis=1)\n",
    "y=df['sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.20,random_state=201)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((770, 5), (770,), (193, 5), (193,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape,ytrain.shape,xtest.shape,ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xtest=scaler.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=np.asarray(ytrain)\n",
    "ytest=np.asarray(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xtrain),type(ytrain),type(xtest),type(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 616 samples, validate on 154 samples\n",
      "Epoch 1/150\n",
      "616/616 [==============================] - 1s 1ms/sample - loss: 219059350.6494 - mse: 219059344.0000 - mae: 11748.3096 - val_loss: 221026249.1429 - val_mse: 221026256.0000 - val_mae: 11894.9834\n",
      "Epoch 2/150\n",
      "616/616 [==============================] - 0s 120us/sample - loss: 219057279.9481 - mse: 219057264.0000 - mae: 11748.2285 - val_loss: 221023979.8442 - val_mse: 221023984.0000 - val_mae: 11894.8965\n",
      "Epoch 3/150\n",
      "616/616 [==============================] - 0s 97us/sample - loss: 219054667.3247 - mse: 219054672.0000 - mae: 11748.1270 - val_loss: 221021006.9610 - val_mse: 221021008.0000 - val_mae: 11894.7822\n",
      "Epoch 4/150\n",
      "616/616 [==============================] - 0s 233us/sample - loss: 219051307.4805 - mse: 219051280.0000 - mae: 11748.0010 - val_loss: 221017291.0130 - val_mse: 221017312.0000 - val_mae: 11894.6416\n",
      "Epoch 5/150\n",
      "616/616 [==============================] - 0s 328us/sample - loss: 219047004.1039 - mse: 219047008.0000 - mae: 11747.8389 - val_loss: 221012339.3247 - val_mse: 221012352.0000 - val_mae: 11894.4512\n",
      "Epoch 6/150\n",
      "616/616 [==============================] - 0s 212us/sample - loss: 219041231.8961 - mse: 219041248.0000 - mae: 11747.6211 - val_loss: 221005705.9740 - val_mse: 221005712.0000 - val_mae: 11894.1992\n",
      "Epoch 7/150\n",
      "616/616 [==============================] - 0s 200us/sample - loss: 219033699.0130 - mse: 219033712.0000 - mae: 11747.3379 - val_loss: 220997294.1299 - val_mse: 220997280.0000 - val_mae: 11893.8828\n",
      "Epoch 8/150\n",
      "616/616 [==============================] - 0s 221us/sample - loss: 219024130.2857 - mse: 219024128.0000 - mae: 11746.9893 - val_loss: 220986917.1948 - val_mse: 220986912.0000 - val_mae: 11893.4932\n",
      "Epoch 9/150\n",
      "616/616 [==============================] - 0s 213us/sample - loss: 219012394.1299 - mse: 219012400.0000 - mae: 11746.5508 - val_loss: 220973873.4545 - val_mse: 220973888.0000 - val_mae: 11893.0059\n",
      "Epoch 10/150\n",
      "616/616 [==============================] - 0s 125us/sample - loss: 218997773.6104 - mse: 218997776.0000 - mae: 11746.0068 - val_loss: 220957640.9351 - val_mse: 220957632.0000 - val_mae: 11892.3984\n",
      "Epoch 11/150\n",
      "616/616 [==============================] - 0s 126us/sample - loss: 218979563.8961 - mse: 218979568.0000 - mae: 11745.3359 - val_loss: 220937952.6234 - val_mse: 220937968.0000 - val_mae: 11891.6631\n",
      "Epoch 12/150\n",
      "616/616 [==============================] - 0s 139us/sample - loss: 218957495.6883 - mse: 218957488.0000 - mae: 11744.5293 - val_loss: 220914034.2857 - val_mse: 220914032.0000 - val_mae: 11890.7705\n",
      "Epoch 13/150\n",
      "616/616 [==============================] - 0s 119us/sample - loss: 218930761.5584 - mse: 218930752.0000 - mae: 11743.5469 - val_loss: 220885348.3636 - val_mse: 220885344.0000 - val_mae: 11889.7002\n",
      "Epoch 14/150\n",
      "616/616 [==============================] - 0s 183us/sample - loss: 218898599.5844 - mse: 218898576.0000 - mae: 11742.3779 - val_loss: 220851736.7273 - val_mse: 220851744.0000 - val_mae: 11888.4492\n",
      "Epoch 15/150\n",
      "616/616 [==============================] - 0s 232us/sample - loss: 218862770.3377 - mse: 218862784.0000 - mae: 11741.0176 - val_loss: 220812022.4416 - val_mse: 220812016.0000 - val_mae: 11886.9707\n",
      "Epoch 16/150\n",
      "616/616 [==============================] - 0s 176us/sample - loss: 218819441.3506 - mse: 218819456.0000 - mae: 11739.4551 - val_loss: 220767846.4416 - val_mse: 220767840.0000 - val_mae: 11885.3281\n",
      "Epoch 17/150\n",
      "616/616 [==============================] - 0s 103us/sample - loss: 218770880.2597 - mse: 218770880.0000 - mae: 11737.6807 - val_loss: 220717223.0649 - val_mse: 220717216.0000 - val_mae: 11883.4443\n",
      "Epoch 18/150\n",
      "616/616 [==============================] - 0s 130us/sample - loss: 218716222.1818 - mse: 218716208.0000 - mae: 11735.6621 - val_loss: 220660035.3247 - val_mse: 220660032.0000 - val_mae: 11881.3184\n",
      "Epoch 19/150\n",
      "616/616 [==============================] - 0s 93us/sample - loss: 218655271.7403 - mse: 218655280.0000 - mae: 11733.4180 - val_loss: 220596348.4675 - val_mse: 220596352.0000 - val_mae: 11878.9482\n",
      "Epoch 20/150\n",
      "616/616 [==============================] - 0s 111us/sample - loss: 218587280.2078 - mse: 218587280.0000 - mae: 11730.9121 - val_loss: 220525919.1688 - val_mse: 220525920.0000 - val_mae: 11876.3281\n",
      "Epoch 21/150\n",
      "616/616 [==============================] - 0s 104us/sample - loss: 218510609.5584 - mse: 218510608.0000 - mae: 11728.1426 - val_loss: 220447816.1039 - val_mse: 220447808.0000 - val_mae: 11873.4258\n",
      "Epoch 22/150\n",
      "616/616 [==============================] - 0s 116us/sample - loss: 218426551.8961 - mse: 218426560.0000 - mae: 11725.0293 - val_loss: 220358643.1169 - val_mse: 220358640.0000 - val_mae: 11870.1133\n",
      "Epoch 23/150\n",
      "616/616 [==============================] - 0s 128us/sample - loss: 218330414.2338 - mse: 218330416.0000 - mae: 11721.5342 - val_loss: 220261454.3377 - val_mse: 220261472.0000 - val_mae: 11866.5000\n",
      "Epoch 24/150\n",
      "616/616 [==============================] - 0s 102us/sample - loss: 218225271.0649 - mse: 218225248.0000 - mae: 11717.6738 - val_loss: 220152347.2208 - val_mse: 220152336.0000 - val_mae: 11862.4443\n",
      "Epoch 25/150\n",
      "616/616 [==============================] - 0s 114us/sample - loss: 218110052.0000 - mse: 218110032.0000 - mae: 11713.3896 - val_loss: 220031798.6494 - val_mse: 220031792.0000 - val_mae: 11857.9639\n",
      "Epoch 26/150\n",
      "616/616 [==============================] - 0s 104us/sample - loss: 217980818.0260 - mse: 217980816.0000 - mae: 11708.6953 - val_loss: 219902005.1948 - val_mse: 219902000.0000 - val_mae: 11853.1396\n",
      "Epoch 27/150\n",
      "616/616 [==============================] - 0s 128us/sample - loss: 217843485.1429 - mse: 217843472.0000 - mae: 11703.6152 - val_loss: 219759819.8442 - val_mse: 219759808.0000 - val_mae: 11847.8535\n",
      "Epoch 28/150\n",
      "616/616 [==============================] - 0s 114us/sample - loss: 217694382.5974 - mse: 217694384.0000 - mae: 11698.0986 - val_loss: 219606666.5974 - val_mse: 219606672.0000 - val_mae: 11842.1572\n",
      "Epoch 29/150\n",
      "616/616 [==============================] - 0s 123us/sample - loss: 217528680.3636 - mse: 217528688.0000 - mae: 11692.1650 - val_loss: 219443091.5325 - val_mse: 219443088.0000 - val_mae: 11836.0742\n",
      "Epoch 30/150\n",
      "616/616 [==============================] - 0s 106us/sample - loss: 217354530.9091 - mse: 217354528.0000 - mae: 11685.7822 - val_loss: 219267483.2208 - val_mse: 219267488.0000 - val_mae: 11829.5400\n",
      "Epoch 31/150\n",
      "616/616 [==============================] - 0s 143us/sample - loss: 217169860.4675 - mse: 217169872.0000 - mae: 11678.9336 - val_loss: 219077078.0260 - val_mse: 219077088.0000 - val_mae: 11822.4521\n",
      "Epoch 32/150\n",
      "616/616 [==============================] - 0s 105us/sample - loss: 216970125.3506 - mse: 216970128.0000 - mae: 11671.6768 - val_loss: 218880832.8312 - val_mse: 218880832.0000 - val_mae: 11815.1387\n",
      "Epoch 33/150\n",
      "616/616 [==============================] - 0s 193us/sample - loss: 216762500.4675 - mse: 216762480.0000 - mae: 11664.0166 - val_loss: 218668906.5974 - val_mse: 218668912.0000 - val_mae: 11807.2461\n",
      "Epoch 34/150\n",
      "616/616 [==============================] - 0s 101us/sample - loss: 216537005.6623 - mse: 216537008.0000 - mae: 11655.8223 - val_loss: 218444207.7922 - val_mse: 218444208.0000 - val_mae: 11798.8662\n",
      "Epoch 35/150\n",
      "616/616 [==============================] - 0s 128us/sample - loss: 216301250.2338 - mse: 216301232.0000 - mae: 11647.0488 - val_loss: 218204381.9221 - val_mse: 218204384.0000 - val_mae: 11789.9209\n",
      "Epoch 36/150\n",
      "616/616 [==============================] - 0s 133us/sample - loss: 216050658.8571 - mse: 216050656.0000 - mae: 11637.7959 - val_loss: 217951382.6494 - val_mse: 217951376.0000 - val_mae: 11780.4775\n",
      "Epoch 37/150\n",
      "616/616 [==============================] - 0s 64us/sample - loss: 215781593.5584 - mse: 215781600.0000 - mae: 11628.0693 - val_loss: 217689366.2338 - val_mse: 217689360.0000 - val_mae: 11770.6885\n",
      "Epoch 38/150\n",
      "616/616 [==============================] - 0s 101us/sample - loss: 215505792.4156 - mse: 215505776.0000 - mae: 11617.8594 - val_loss: 217407994.5974 - val_mse: 217408000.0000 - val_mae: 11760.1689\n",
      "Epoch 39/150\n",
      "616/616 [==============================] - 0s 88us/sample - loss: 215216496.1039 - mse: 215216496.0000 - mae: 11606.9219 - val_loss: 217108697.5584 - val_mse: 217108688.0000 - val_mae: 11748.9785\n",
      "Epoch 40/150\n",
      "616/616 [==============================] - 0s 110us/sample - loss: 214900989.9740 - mse: 214900976.0000 - mae: 11595.4844 - val_loss: 216801062.0260 - val_mse: 216801056.0000 - val_mae: 11737.4570\n",
      "Epoch 41/150\n",
      "616/616 [==============================] - 0s 96us/sample - loss: 214579422.3117 - mse: 214579424.0000 - mae: 11583.5029 - val_loss: 216475073.8701 - val_mse: 216475072.0000 - val_mae: 11725.2383\n",
      "Epoch 42/150\n",
      "616/616 [==============================] - 0s 94us/sample - loss: 214242099.0130 - mse: 214242112.0000 - mae: 11571.1084 - val_loss: 216144113.6623 - val_mse: 216144096.0000 - val_mae: 11712.8174\n",
      "Epoch 43/150\n",
      "616/616 [==============================] - 0s 102us/sample - loss: 213887944.3117 - mse: 213887936.0000 - mae: 11558.0225 - val_loss: 215785691.8442 - val_mse: 215785696.0000 - val_mae: 11699.3643\n",
      "Epoch 44/150\n",
      "616/616 [==============================] - 0s 112us/sample - loss: 213514228.7792 - mse: 213514224.0000 - mae: 11544.0811 - val_loss: 215410697.9740 - val_mse: 215410688.0000 - val_mae: 11685.2764\n",
      "Epoch 45/150\n",
      "616/616 [==============================] - 0s 112us/sample - loss: 213119990.5455 - mse: 213119984.0000 - mae: 11529.6133 - val_loss: 215023540.3636 - val_mse: 215023520.0000 - val_mae: 11670.7031\n",
      "Epoch 46/150\n",
      "616/616 [==============================] - 0s 86us/sample - loss: 212717917.4026 - mse: 212717904.0000 - mae: 11514.6299 - val_loss: 214620301.0909 - val_mse: 214620288.0000 - val_mae: 11655.5127\n",
      "Epoch 47/150\n",
      "616/616 [==============================] - 0s 70us/sample - loss: 212296661.9740 - mse: 212296672.0000 - mae: 11498.9834 - val_loss: 214201640.9351 - val_mse: 214201632.0000 - val_mae: 11639.7139\n",
      "Epoch 48/150\n",
      "616/616 [==============================] - 0s 69us/sample - loss: 211864574.3377 - mse: 211864576.0000 - mae: 11482.6104 - val_loss: 213761000.1039 - val_mse: 213760992.0000 - val_mae: 11623.0840\n",
      "Epoch 49/150\n",
      "616/616 [==============================] - 0s 71us/sample - loss: 211407955.8961 - mse: 211407952.0000 - mae: 11465.7676 - val_loss: 213314729.9740 - val_mse: 213314736.0000 - val_mae: 11606.2051\n",
      "Epoch 50/150\n",
      "616/616 [==============================] - 0s 115us/sample - loss: 210942145.7662 - mse: 210942144.0000 - mae: 11448.3271 - val_loss: 212850865.6623 - val_mse: 212850880.0000 - val_mae: 11588.6396\n",
      "Epoch 51/150\n",
      "616/616 [==============================] - 0s 105us/sample - loss: 210465192.2857 - mse: 210465168.0000 - mae: 11430.2178 - val_loss: 212367351.6883 - val_mse: 212367344.0000 - val_mae: 11570.3193\n",
      "Epoch 52/150\n",
      "616/616 [==============================] - 0s 123us/sample - loss: 209957572.0000 - mse: 209957600.0000 - mae: 11411.5498 - val_loss: 211878233.9740 - val_mse: 211878240.0000 - val_mae: 11551.7441\n",
      "Epoch 53/150\n",
      "616/616 [==============================] - 0s 114us/sample - loss: 209440577.1429 - mse: 209440560.0000 - mae: 11392.1758 - val_loss: 211358407.8961 - val_mse: 211358416.0000 - val_mae: 11531.9727\n",
      "Epoch 54/150\n",
      "616/616 [==============================] - 0s 76us/sample - loss: 208902888.5195 - mse: 208902880.0000 - mae: 11371.9189 - val_loss: 210819252.9870 - val_mse: 210819248.0000 - val_mae: 11511.4336\n",
      "Epoch 55/150\n",
      "616/616 [==============================] - 0s 95us/sample - loss: 208347370.8052 - mse: 208347392.0000 - mae: 11350.9844 - val_loss: 210269672.7273 - val_mse: 210269664.0000 - val_mae: 11490.4688\n",
      "Epoch 56/150\n",
      "616/616 [==============================] - 0s 69us/sample - loss: 207764210.9091 - mse: 207764224.0000 - mae: 11329.4980 - val_loss: 209711760.6234 - val_mse: 209711776.0000 - val_mae: 11469.1475\n",
      "Epoch 57/150\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 207177033.9481 - mse: 207177040.0000 - mae: 11307.3047 - val_loss: 209117773.5065 - val_mse: 209117776.0000 - val_mae: 11446.4102\n",
      "Epoch 58/150\n",
      "616/616 [==============================] - 0s 82us/sample - loss: 206563178.1818 - mse: 206563152.0000 - mae: 11284.0215 - val_loss: 208513035.6364 - val_mse: 208513040.0000 - val_mae: 11423.2031\n",
      "Epoch 59/150\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 205936779.6883 - mse: 205936800.0000 - mae: 11260.4219 - val_loss: 207894864.2078 - val_mse: 207894864.0000 - val_mae: 11399.4385\n",
      "Epoch 60/150\n",
      "616/616 [==============================] - 0s 103us/sample - loss: 205286021.4026 - mse: 205286016.0000 - mae: 11235.7139 - val_loss: 207247372.2597 - val_mse: 207247376.0000 - val_mae: 11374.5127\n",
      "Epoch 61/150\n",
      "616/616 [==============================] - 0s 140us/sample - loss: 204613840.5195 - mse: 204613824.0000 - mae: 11210.2432 - val_loss: 206586566.8571 - val_mse: 206586560.0000 - val_mae: 11349.0146\n",
      "Epoch 62/150\n",
      "616/616 [==============================] - 0s 70us/sample - loss: 203931423.3506 - mse: 203931440.0000 - mae: 11184.1396 - val_loss: 205906049.2468 - val_mse: 205906048.0000 - val_mae: 11322.7031\n",
      "Epoch 63/150\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 203224556.2597 - mse: 203224560.0000 - mae: 11157.0215 - val_loss: 205204169.5584 - val_mse: 205204176.0000 - val_mae: 11295.5322\n",
      "Epoch 64/150\n",
      "616/616 [==============================] - 0s 102us/sample - loss: 202492825.5584 - mse: 202492832.0000 - mae: 11129.2178 - val_loss: 204484233.1429 - val_mse: 204484240.0000 - val_mae: 11267.9902\n",
      "Epoch 65/150\n",
      "616/616 [==============================] - 0s 140us/sample - loss: 201746261.2468 - mse: 201746240.0000 - mae: 11100.9941 - val_loss: 203755178.8052 - val_mse: 203755168.0000 - val_mae: 11240.0273\n",
      "Epoch 66/150\n",
      "616/616 [==============================] - 0s 87us/sample - loss: 200992701.2987 - mse: 200992688.0000 - mae: 11072.2090 - val_loss: 202995086.1299 - val_mse: 202995088.0000 - val_mae: 11210.7979\n",
      "Epoch 67/150\n",
      "616/616 [==============================] - 0s 81us/sample - loss: 200207313.9740 - mse: 200207280.0000 - mae: 11042.5166 - val_loss: 202228992.6234 - val_mse: 202228992.0000 - val_mae: 11181.2666\n",
      "Epoch 68/150\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 199406967.9481 - mse: 199406960.0000 - mae: 11012.3037 - val_loss: 201429981.2987 - val_mse: 201429984.0000 - val_mae: 11150.3994\n",
      "Epoch 69/150\n",
      "616/616 [==============================] - 0s 109us/sample - loss: 198592744.3117 - mse: 198592768.0000 - mae: 10980.7793 - val_loss: 200622339.3247 - val_mse: 200622352.0000 - val_mae: 11119.1182\n",
      "Epoch 70/150\n",
      "616/616 [==============================] - 0s 92us/sample - loss: 197756390.3377 - mse: 197756384.0000 - mae: 10949.1631 - val_loss: 199795876.1558 - val_mse: 199795856.0000 - val_mae: 11087.0029\n",
      "Epoch 71/150\n",
      "616/616 [==============================] - 0s 139us/sample - loss: 196906052.7792 - mse: 196906064.0000 - mae: 10917.3008 - val_loss: 198968054.4416 - val_mse: 198968048.0000 - val_mae: 11054.7354\n",
      "Epoch 72/150\n",
      "616/616 [==============================] - 0s 92us/sample - loss: 196048088.9870 - mse: 196048096.0000 - mae: 10884.7793 - val_loss: 198131904.8312 - val_mse: 198131904.0000 - val_mae: 11022.0811\n",
      "Epoch 73/150\n",
      "616/616 [==============================] - 0s 105us/sample - loss: 195181281.2987 - mse: 195181296.0000 - mae: 10851.6260 - val_loss: 197258078.5455 - val_mse: 197258080.0000 - val_mae: 10988.1807\n",
      "Epoch 74/150\n",
      "616/616 [==============================] - 0s 90us/sample - loss: 194283986.3377 - mse: 194283984.0000 - mae: 10817.9502 - val_loss: 196386544.6234 - val_mse: 196386544.0000 - val_mae: 10954.2666\n",
      "Epoch 75/150\n",
      "616/616 [==============================] - 0s 129us/sample - loss: 193372835.3766 - mse: 193372832.0000 - mae: 10783.3652 - val_loss: 195479868.2597 - val_mse: 195479856.0000 - val_mae: 10918.8535\n",
      "Epoch 76/150\n",
      "616/616 [==============================] - 0s 74us/sample - loss: 192419484.8312 - mse: 192419472.0000 - mae: 10747.8809 - val_loss: 194557811.5325 - val_mse: 194557824.0000 - val_mae: 10882.7559\n",
      "Epoch 77/150\n",
      "616/616 [==============================] - 0s 69us/sample - loss: 191475856.0000 - mse: 191475840.0000 - mae: 10712.0674 - val_loss: 193616560.0000 - val_mse: 193616560.0000 - val_mae: 10846.0137\n",
      "Epoch 78/150\n",
      "616/616 [==============================] - 0s 107us/sample - loss: 190496834.3377 - mse: 190496816.0000 - mae: 10675.1611 - val_loss: 192666214.8571 - val_mse: 192666208.0000 - val_mae: 10809.0264\n",
      "Epoch 79/150\n",
      "616/616 [==============================] - 0s 141us/sample - loss: 189506689.5584 - mse: 189506688.0000 - mae: 10637.8496 - val_loss: 191667603.9481 - val_mse: 191667600.0000 - val_mae: 10770.2559\n",
      "Epoch 80/150\n",
      "616/616 [==============================] - 0s 75us/sample - loss: 188476601.1948 - mse: 188476608.0000 - mae: 10599.3867 - val_loss: 190677422.1299 - val_mse: 190677424.0000 - val_mae: 10731.8682\n",
      "Epoch 81/150\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 187454730.4935 - mse: 187454736.0000 - mae: 10560.5645 - val_loss: 189673334.2338 - val_mse: 189673344.0000 - val_mae: 10693.2197\n",
      "Epoch 82/150\n",
      "616/616 [==============================] - 0s 97us/sample - loss: 186419617.4026 - mse: 186419616.0000 - mae: 10521.6787 - val_loss: 188640287.1688 - val_mse: 188640288.0000 - val_mae: 10653.4648\n",
      "Epoch 83/150\n",
      "616/616 [==============================] - 0s 75us/sample - loss: 185351749.4545 - mse: 185351760.0000 - mae: 10481.6328 - val_loss: 187595533.9221 - val_mse: 187595536.0000 - val_mae: 10613.8086\n",
      "Epoch 84/150\n",
      "616/616 [==============================] - 0s 71us/sample - loss: 184278176.4675 - mse: 184278192.0000 - mae: 10441.0000 - val_loss: 186545742.5455 - val_mse: 186545744.0000 - val_mae: 10574.6172\n",
      "Epoch 85/150\n",
      "616/616 [==============================] - 0s 72us/sample - loss: 183192790.4675 - mse: 183192768.0000 - mae: 10399.5967 - val_loss: 185485100.2597 - val_mse: 185485120.0000 - val_mae: 10534.8672\n",
      "Epoch 86/150\n",
      "616/616 [==============================] - 0s 110us/sample - loss: 182101420.2597 - mse: 182101424.0000 - mae: 10357.8135 - val_loss: 184386945.8701 - val_mse: 184386944.0000 - val_mae: 10493.5459\n",
      "Epoch 87/150\n",
      "616/616 [==============================] - 0s 139us/sample - loss: 180976195.4545 - mse: 180976192.0000 - mae: 10315.5068 - val_loss: 183285339.4286 - val_mse: 183285328.0000 - val_mae: 10451.9209\n",
      "Epoch 88/150\n",
      "616/616 [==============================] - 0s 96us/sample - loss: 179834315.1688 - mse: 179834320.0000 - mae: 10273.2871 - val_loss: 182189748.7792 - val_mse: 182189760.0000 - val_mae: 10410.5117\n",
      "Epoch 89/150\n",
      "616/616 [==============================] - 0s 98us/sample - loss: 178698543.5325 - mse: 178698544.0000 - mae: 10229.8877 - val_loss: 181056118.0260 - val_mse: 181056128.0000 - val_mae: 10368.0166\n",
      "Epoch 90/150\n",
      "616/616 [==============================] - 0s 110us/sample - loss: 177532916.1039 - mse: 177532896.0000 - mae: 10186.3887 - val_loss: 179931636.5714 - val_mse: 179931632.0000 - val_mae: 10326.1484\n",
      "Epoch 91/150\n",
      "616/616 [==============================] - 0s 88us/sample - loss: 176365959.8182 - mse: 176365952.0000 - mae: 10143.1934 - val_loss: 178790069.6104 - val_mse: 178790080.0000 - val_mae: 10283.6406\n",
      "Epoch 92/150\n",
      "616/616 [==============================] - 0s 74us/sample - loss: 175206145.2987 - mse: 175206160.0000 - mae: 10099.2861 - val_loss: 177596887.6883 - val_mse: 177596864.0000 - val_mae: 10239.4492\n",
      "Epoch 93/150\n",
      "616/616 [==============================] - 0s 72us/sample - loss: 174001487.7922 - mse: 174001488.0000 - mae: 10053.9971 - val_loss: 176423852.0519 - val_mse: 176423856.0000 - val_mae: 10196.2500\n",
      "Epoch 94/150\n",
      "616/616 [==============================] - 0s 73us/sample - loss: 172781076.2597 - mse: 172781088.0000 - mae: 10009.1562 - val_loss: 175251721.5584 - val_mse: 175251728.0000 - val_mae: 10153.1357\n",
      "Epoch 95/150\n",
      "616/616 [==============================] - 0s 85us/sample - loss: 171558227.9740 - mse: 171558224.0000 - mae: 9963.5889 - val_loss: 174064865.0390 - val_mse: 174064848.0000 - val_mae: 10109.2705\n",
      "Epoch 96/150\n",
      "616/616 [==============================] - 0s 112us/sample - loss: 170329199.4286 - mse: 170329200.0000 - mae: 9916.8789 - val_loss: 172831138.7013 - val_mse: 172831136.0000 - val_mae: 10063.4648\n",
      "Epoch 97/150\n",
      "616/616 [==============================] - 0s 163us/sample - loss: 169047302.1558 - mse: 169047296.0000 - mae: 9869.0488 - val_loss: 171590855.0649 - val_mse: 171590848.0000 - val_mae: 10017.8193\n",
      "Epoch 98/150\n",
      "616/616 [==============================] - 0s 107us/sample - loss: 167786400.0519 - mse: 167786416.0000 - mae: 9821.4355 - val_loss: 170350183.2727 - val_mse: 170350176.0000 - val_mae: 9972.8154\n",
      "Epoch 99/150\n",
      "616/616 [==============================] - 0s 83us/sample - loss: 166521971.7662 - mse: 166521984.0000 - mae: 9774.3242 - val_loss: 169090469.8182 - val_mse: 169090480.0000 - val_mae: 9926.9814\n",
      "Epoch 100/150\n",
      "616/616 [==============================] - 0s 63us/sample - loss: 165231543.8701 - mse: 165231536.0000 - mae: 9726.9980 - val_loss: 167869399.2727 - val_mse: 167869392.0000 - val_mae: 9882.8740\n",
      "Epoch 101/150\n",
      "616/616 [==============================] - 0s 59us/sample - loss: 163975762.8052 - mse: 163975744.0000 - mae: 9679.0977 - val_loss: 166600003.9481 - val_mse: 166600016.0000 - val_mae: 9836.8154\n",
      "Epoch 102/150\n",
      "616/616 [==============================] - 0s 63us/sample - loss: 162682680.5974 - mse: 162682672.0000 - mae: 9630.5010 - val_loss: 165333942.6494 - val_mse: 165333936.0000 - val_mae: 9790.6250\n",
      "Epoch 103/150\n",
      "616/616 [==============================] - 0s 67us/sample - loss: 161377116.9610 - mse: 161377120.0000 - mae: 9581.8682 - val_loss: 164050685.5065 - val_mse: 164050688.0000 - val_mae: 9743.5342\n",
      "Epoch 104/150\n",
      "616/616 [==============================] - ETA: 0s - loss: 162732384.0000 - mse: 162732384.0000 - mae: 9061.35 - 0s 62us/sample - loss: 160075801.8701 - mse: 160075792.0000 - mae: 9532.6338 - val_loss: 162763798.6494 - val_mse: 162763808.0000 - val_mae: 9696.0557\n",
      "Epoch 105/150\n",
      "616/616 [==============================] - 0s 95us/sample - loss: 158736746.0779 - mse: 158736752.0000 - mae: 9483.5742 - val_loss: 161467917.7143 - val_mse: 161467904.0000 - val_mae: 9647.9453\n",
      "Epoch 106/150\n",
      "616/616 [==============================] - 0s 110us/sample - loss: 157391279.1948 - mse: 157391280.0000 - mae: 9434.1250 - val_loss: 160187781.7143 - val_mse: 160187776.0000 - val_mae: 9600.4990\n",
      "Epoch 107/150\n",
      "616/616 [==============================] - 0s 66us/sample - loss: 156054985.0390 - mse: 156054976.0000 - mae: 9385.4521 - val_loss: 158882474.3896 - val_mse: 158882464.0000 - val_mae: 9552.4023\n",
      "Epoch 108/150\n",
      "616/616 [==============================] - 0s 155us/sample - loss: 154716676.8312 - mse: 154716688.0000 - mae: 9334.7129 - val_loss: 157514320.1039 - val_mse: 157514320.0000 - val_mae: 9501.8584\n",
      "Epoch 109/150\n",
      "616/616 [==============================] - 0s 64us/sample - loss: 153312518.8571 - mse: 153312512.0000 - mae: 9282.8506 - val_loss: 156157501.2987 - val_mse: 156157520.0000 - val_mae: 9451.4043\n",
      "Epoch 110/150\n",
      "616/616 [==============================] - 0s 64us/sample - loss: 151925477.1429 - mse: 151925488.0000 - mae: 9231.9463 - val_loss: 154783858.0779 - val_mse: 154783856.0000 - val_mae: 9400.0068\n",
      "Epoch 111/150\n",
      "616/616 [==============================] - 0s 60us/sample - loss: 150525751.6883 - mse: 150525744.0000 - mae: 9180.1113 - val_loss: 153427958.6494 - val_mse: 153427952.0000 - val_mae: 9349.0312\n",
      "Epoch 112/150\n",
      "616/616 [==============================] - 0s 61us/sample - loss: 149140785.8961 - mse: 149140784.0000 - mae: 9129.0537 - val_loss: 152057020.3636 - val_mse: 152057024.0000 - val_mae: 9297.4336\n",
      "Epoch 113/150\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 147726413.4026 - mse: 147726416.0000 - mae: 9078.3584 - val_loss: 150706977.6623 - val_mse: 150706976.0000 - val_mae: 9246.2695\n",
      "Epoch 114/150\n",
      "616/616 [==============================] - 0s 103us/sample - loss: 146354472.1299 - mse: 146354464.0000 - mae: 9028.0332 - val_loss: 149352640.4156 - val_mse: 149352640.0000 - val_mae: 9194.5918\n",
      "Epoch 115/150\n",
      "616/616 [==============================] - 0s 102us/sample - loss: 144969135.1948 - mse: 144969136.0000 - mae: 8979.4150 - val_loss: 147976162.9091 - val_mse: 147976160.0000 - val_mae: 9141.7217\n",
      "Epoch 116/150\n",
      "616/616 [==============================] - 0s 77us/sample - loss: 143556001.9221 - mse: 143556016.0000 - mae: 8929.3008 - val_loss: 146657688.9351 - val_mse: 146657696.0000 - val_mae: 9090.7393\n",
      "Epoch 117/150\n",
      "616/616 [==============================] - 0s 62us/sample - loss: 142199927.0909 - mse: 142199920.0000 - mae: 8881.4277 - val_loss: 145281853.5065 - val_mse: 145281856.0000 - val_mae: 9037.7188\n",
      "Epoch 118/150\n",
      "616/616 [==============================] - 0s 79us/sample - loss: 140818716.9091 - mse: 140818704.0000 - mae: 8831.7549 - val_loss: 143919439.7922 - val_mse: 143919456.0000 - val_mae: 8985.6807\n",
      "Epoch 119/150\n",
      "616/616 [==============================] - 0s 72us/sample - loss: 139413551.5844 - mse: 139413536.0000 - mae: 8781.3672 - val_loss: 142564639.6883 - val_mse: 142564640.0000 - val_mae: 8933.8916\n",
      "Epoch 120/150\n",
      "616/616 [==============================] - 0s 68us/sample - loss: 138008548.1558 - mse: 138008544.0000 - mae: 8733.1182 - val_loss: 141198204.6753 - val_mse: 141198208.0000 - val_mae: 8881.3555\n",
      "Epoch 121/150\n",
      "616/616 [==============================] - 0s 63us/sample - loss: 136611608.5195 - mse: 136611616.0000 - mae: 8683.3066 - val_loss: 139802328.2078 - val_mse: 139802336.0000 - val_mae: 8828.2793\n",
      "Epoch 122/150\n",
      "616/616 [==============================] - 0s 62us/sample - loss: 135185461.2468 - mse: 135185456.0000 - mae: 8632.2090 - val_loss: 138401937.2468 - val_mse: 138401952.0000 - val_mae: 8775.3760\n",
      "Epoch 123/150\n",
      "616/616 [==============================] - 0s 63us/sample - loss: 133751135.5325 - mse: 133751128.0000 - mae: 8582.8066 - val_loss: 137013590.7532 - val_mse: 137013584.0000 - val_mae: 8723.7861\n",
      "Epoch 124/150\n",
      "616/616 [==============================] - 0s 64us/sample - loss: 132311945.0130 - mse: 132311944.0000 - mae: 8532.8223 - val_loss: 135628185.8701 - val_mse: 135628192.0000 - val_mae: 8674.0312\n",
      "Epoch 125/150\n",
      "616/616 [==============================] - 0s 63us/sample - loss: 130896574.1818 - mse: 130896560.0000 - mae: 8484.2803 - val_loss: 134230195.9481 - val_mse: 134230208.0000 - val_mae: 8623.7158\n",
      "Epoch 126/150\n",
      "616/616 [==============================] - 0s 65us/sample - loss: 129498381.1429 - mse: 129498376.0000 - mae: 8435.5576 - val_loss: 132830506.7013 - val_mse: 132830504.0000 - val_mae: 8573.5068\n",
      "Epoch 127/150\n",
      "616/616 [==============================] - 0s 70us/sample - loss: 128048871.5065 - mse: 128048856.0000 - mae: 8388.2051 - val_loss: 131484200.6234 - val_mse: 131484208.0000 - val_mae: 8524.7881\n",
      "Epoch 128/150\n",
      "616/616 [==============================] - 0s 72us/sample - loss: 126663832.8052 - mse: 126663840.0000 - mae: 8339.9209 - val_loss: 130088941.1948 - val_mse: 130088944.0000 - val_mae: 8473.9746\n",
      "Epoch 129/150\n",
      "616/616 [==============================] - 0s 67us/sample - loss: 125260039.3506 - mse: 125260040.0000 - mae: 8293.4619 - val_loss: 128703708.2597 - val_mse: 128703712.0000 - val_mae: 8423.7139\n",
      "Epoch 130/150\n",
      "616/616 [==============================] - 0s 68us/sample - loss: 123849503.1948 - mse: 123849504.0000 - mae: 8244.6807 - val_loss: 127348559.5844 - val_mse: 127348560.0000 - val_mae: 8374.1094\n",
      "Epoch 131/150\n",
      "616/616 [==============================] - 0s 76us/sample - loss: 122461586.0779 - mse: 122461600.0000 - mae: 8199.1348 - val_loss: 125948680.9351 - val_mse: 125948672.0000 - val_mae: 8323.1230\n",
      "Epoch 132/150\n",
      "616/616 [==============================] - 0s 103us/sample - loss: 121053008.0260 - mse: 121053008.0000 - mae: 8152.7485 - val_loss: 124575884.3636 - val_mse: 124575888.0000 - val_mae: 8273.6016\n",
      "Epoch 133/150\n",
      "616/616 [==============================] - 0s 123us/sample - loss: 119612442.5195 - mse: 119612456.0000 - mae: 8104.3101 - val_loss: 123260497.4545 - val_mse: 123260488.0000 - val_mae: 8226.0723\n",
      "Epoch 134/150\n",
      "616/616 [==============================] - 0s 104us/sample - loss: 118273409.5584 - mse: 118273408.0000 - mae: 8059.6616 - val_loss: 121860535.8961 - val_mse: 121860536.0000 - val_mae: 8175.4941\n",
      "Epoch 135/150\n",
      "616/616 [==============================] - 0s 117us/sample - loss: 116833357.6364 - mse: 116833360.0000 - mae: 8012.1040 - val_loss: 120514188.0519 - val_mse: 120514200.0000 - val_mae: 8126.6484\n",
      "Epoch 136/150\n",
      "616/616 [==============================] - 0s 63us/sample - loss: 115511691.8312 - mse: 115511696.0000 - mae: 7966.6729 - val_loss: 119144045.8182 - val_mse: 119144048.0000 - val_mae: 8078.9033\n",
      "Epoch 137/150\n",
      "616/616 [==============================] - 0s 68us/sample - loss: 114103287.3247 - mse: 114103280.0000 - mae: 7919.6665 - val_loss: 117823239.0649 - val_mse: 117823232.0000 - val_mae: 8034.5366\n",
      "Epoch 138/150\n",
      "616/616 [==============================] - 0s 74us/sample - loss: 112735380.5974 - mse: 112735392.0000 - mae: 7875.6460 - val_loss: 116497955.4286 - val_mse: 116497952.0000 - val_mae: 7990.3335\n",
      "Epoch 139/150\n",
      "616/616 [==============================] - 0s 71us/sample - loss: 111378869.6364 - mse: 111378864.0000 - mae: 7829.9058 - val_loss: 115130817.7662 - val_mse: 115130824.0000 - val_mae: 7944.2817\n",
      "Epoch 140/150\n",
      "616/616 [==============================] - 0s 72us/sample - loss: 109997694.1039 - mse: 109997704.0000 - mae: 7784.9634 - val_loss: 113817571.0130 - val_mse: 113817576.0000 - val_mae: 7900.2661\n",
      "Epoch 141/150\n",
      "616/616 [==============================] - 0s 106us/sample - loss: 108678293.3506 - mse: 108678304.0000 - mae: 7740.3237 - val_loss: 112491070.0260 - val_mse: 112491064.0000 - val_mae: 7855.7661\n",
      "Epoch 142/150\n",
      "616/616 [==============================] - 0s 111us/sample - loss: 107326957.4805 - mse: 107326960.0000 - mae: 7696.4819 - val_loss: 111169808.2078 - val_mse: 111169808.0000 - val_mae: 7811.5420\n",
      "Epoch 143/150\n",
      "616/616 [==============================] - 0s 139us/sample - loss: 105971455.4805 - mse: 105971456.0000 - mae: 7650.6191 - val_loss: 109889394.7013 - val_mse: 109889392.0000 - val_mae: 7769.5132\n",
      "Epoch 144/150\n",
      "616/616 [==============================] - 0s 110us/sample - loss: 104684292.1818 - mse: 104684288.0000 - mae: 7610.4458 - val_loss: 108618628.7792 - val_mse: 108618632.0000 - val_mae: 7727.7295\n",
      "Epoch 145/150\n",
      "616/616 [==============================] - 0s 84us/sample - loss: 103364730.7792 - mse: 103364736.0000 - mae: 7565.9531 - val_loss: 107343281.6623 - val_mse: 107343280.0000 - val_mae: 7685.5688\n",
      "Epoch 146/150\n",
      "616/616 [==============================] - 0s 94us/sample - loss: 102079901.0130 - mse: 102079904.0000 - mae: 7523.3330 - val_loss: 106045653.8182 - val_mse: 106045656.0000 - val_mae: 7642.8540\n",
      "Epoch 147/150\n",
      "616/616 [==============================] - 0s 89us/sample - loss: 100762219.0390 - mse: 100762216.0000 - mae: 7481.5615 - val_loss: 104759901.4026 - val_mse: 104759904.0000 - val_mae: 7601.1743\n",
      "Epoch 148/150\n",
      "616/616 [==============================] - 0s 71us/sample - loss: 99458265.6364 - mse: 99458264.0000 - mae: 7438.3184 - val_loss: 103503946.4935 - val_mse: 103503944.0000 - val_mae: 7559.9839\n",
      "Epoch 149/150\n",
      "616/616 [==============================] - 0s 67us/sample - loss: 98202769.4026 - mse: 98202776.0000 - mae: 7397.6816 - val_loss: 102264523.1169 - val_mse: 102264528.0000 - val_mae: 7520.6250\n",
      "Epoch 150/150\n",
      "616/616 [==============================] - 0s 91us/sample - loss: 96920614.1039 - mse: 96920608.0000 - mae: 7355.4985 - val_loss: 101045901.4026 - val_mse: 101045896.0000 - val_mae: 7482.4790\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain, ytrain, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value=model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value=predicted_value.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame({'Actual':ytest,'Predicted':predicted_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7960</td>\n",
       "      <td>4470.063477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23894</td>\n",
       "      <td>7050.045410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15064</td>\n",
       "      <td>6434.330566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16803</td>\n",
       "      <td>7989.776367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25470</td>\n",
       "      <td>7495.109863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual    Predicted\n",
       "0    7960  4470.063477\n",
       "1   23894  7050.045410\n",
       "2   15064  6434.330566\n",
       "3   16803  7989.776367\n",
       "4   25470  7495.109863"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new Data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X=[  40.    0.   26. 9000. 8000.], Predicted=[5017.2554]\n"
     ]
    }
   ],
   "source": [
    "xnew = np.array([[40, 0, 26, 9000, 8000]])\n",
    "xnew= scaler.transform(xnew)\n",
    "ynew= model.predict(xnew)\n",
    "#invert normalize\n",
    "#ynew = scaler_y.inverse_transform(ynew) \n",
    "xnew1 = scaler.inverse_transform(xnew)\n",
    "print(\"X=%s, Predicted=%s\" % (xnew1[0], ynew[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
